data(cpp_imputed)
covars <- c("apgar1", "apgar5", "parity", "gagebrth", "mage", "meducyrs", "sexn")
outcome <- "haz"
task <- sl3_Task$new(data.table::copy(cpp_imputed), covariates = covars, outcome = outcome)
task2 <- sl3_Task$new(data.table::copy(cpp_imputed), covariates = covars, outcome = outcome)
glm_learner <- Lrnr_glm$new()
glmnet_learner <- Lrnr_pkg_SuperLearner$new("SL.glmnet")
subset_apgar <- Lrnr_subset_covariates$new(covariates = c("apgar1", "apgar5"))
learners <- list(glm_learner, glmnet_learner, subset_apgar)
sl1 <- make_learner(Lrnr_sl, learners, glm_learner)
# sl3_debug_mode()
# debugonce(sl1$.__enclos_env__$private$.train)
# debugonce(sl1$.__enclos_env__$private$.train_sublearners)
sl1_fit <- sl1$train(task)
sl1_pred <- sl1_fit$predict()
head(sl1_pred)
sl1_fit
library(origami)
g0 <- function(W) {
W1 <- W[, 1]
scale_factor <- 0.8
A <- plogis(scale_factor * W1)
}
gen_data <- function(n = 1000, p = 4) {
W <- matrix(rnorm(n * p), nrow = n)
colnames(W) <- paste("W", seq_len(p), sep = "")
g0W <- g0(W)
A <- rbinom(n, 1, g0W)
u <- runif(n)
df <- data.frame(W, A)
df$g0W <- g0(W)
return(df)
}
set.seed(1234)
data <- gen_data(1000)
Wnodes <- grep("^W", names(data), value = TRUE)
Anode <- "A"
task <- sl3_Task$new(data, covariates = Wnodes, outcome = Anode)
# define learners
learners <- list(
rf = make_learner(Lrnr_randomForest),
xgb = make_learner(Lrnr_xgboost),
glmnet = make_learner(Lrnr_glmnet),
glm_fast = make_learner(Lrnr_glm_fast),
glm_fast_true_covars = make_learner(Lrnr_glm_fast, covariates = "W1"),
mean = make_learner(Lrnr_mean)
)
# define metalearner
logit_metalearner <- make_learner(
Lrnr_optim,
loss_function = loss_loglik_binomial,
learner_function = metalearner_logistic_binomial
# define metalearner
logit_metalearner <- make_learner(
Lrnr_optim,
loss_function = loss_loglik_binomial,
learner_function = metalearner_logistic_binomial
)
# define metalearner
logit_metalearner <- make_learner(
Lrnr_optim,
loss_function = loss_loglik_binomial,
learner_function = metalearner_logistic_binomial
)
binom_sl <- make_learner(Lrnr_sl, learners, logit_metalearner)
sl_fit <- binom_sl$train(task)
coef(sl_fit$fit_object$cv_meta_fit)
preds <- sl_fit$predict()
source('~/.active-rstudio-document', echo=TRUE)
preds
set.seed(49753)
suppressMessages(library(data.table))
library(dplyr)
library(SuperLearner)
library(origami)
library(sl3)
# load example data set
data(cpp)
cpp <- cpp %>%
dplyr::filter(!is.na(haz)) %>%
mutate_all(funs(replace(., is.na(.), 0)))
# use covariates of intest and the outcome to build a task object
covars <- c("apgar1", "apgar5", "parity", "gagebrth", "mage", "meducyrs",
"sexn")
task <- sl3_Task$new(cpp, covariates = covars, outcome = "haz")
# set up screeners and learners via built-in functions and pipelines
slscreener <- Lrnr_pkg_SuperLearner_screener$new("screen.glmnet")
glm_learner <- Lrnr_glm$new()
screen_and_glm <- Pipeline$new(slscreener, glm_learner)
SL.glmnet_learner <- Lrnr_pkg_SuperLearner$new(SL_wrapper = "SL.glmnet")
# stack learners into a model (including screeners and pipelines)
learner_stack <- Stack$new(SL.glmnet_learner, glm_learner, screen_and_glm)
stack_fit <- learner_stack$train(task)
preds <- stack_fit$predict()
head(preds)
getwd
getwd()
remotes::install_github("tmleCommunity")
remotes::install_github("chizhangucb/tmleCommunity")
library(tmleCommunity)
tmleCommunity
help(BinaryOutModel)
BinaryOutModel
BinaryOutModel
tmleCommunity:::fit_single_reg
tmleCommunity:::fit_single_reg.sl3S3()
tmleCommunity:::fit_single_reg.sl3S3
.libPaths()
remotes::install_github("chizhangucb/tmleCommunity")
tmleCommunity:::fit_single_reg.sl3S3
library(tmleCommunity)
tmleCommunity:::fit_single_reg.sl3S3
library(tmleCommunity)
tmleCommunity:::fit_single_reg.sl3S3
get.iid.dat.Abin <- function(ndata = 100000, rndseed = NULL, is.Y.bin = TRUE) {
require(simcausal)
D <- DAG.empty()
D <- D +
node("W1", distr = "rbern", prob = 0.5) +
node("W2", distr = "rbern", prob = 0.3) +
node("W3", distr = "rnorm", mean = 0, sd = 0.3) +
node("W4", distr = "runif", min = 0, max = 1) +
node("W3W4", distr = "rconst", const = W3 * W4) +
node("A", distr = "rbern", prob = plogis(0.86 * W1 + W2 + 1.32 * W3 - W4 - 0.45 *W3W4 + 0.1)) +
node("Y", distr = "rnorm", mean = (2.8 * A + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y1", distr = "rnorm", mean = (2.8 * 1 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y0", distr = "rnorm", mean = (2.8 * 0 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1)
D <- set.DAG(D)
Odata <- sim(D, n = ndata, rndseed = rndseed)
psi0.Y <- mean(Odata$Y1) - mean(Odata$Y0)
print("psi0.Y: " %+% psi0.Y)
return(list(psi0.Y = psi0.Y, Odata = Odata))
}
`%+%` <- function(a, b) paste0(a, b)
ndata <- 10000
rndseed <- 12345
indPop.iid.bA.cY <- get.iid.dat.Abin(ndata = 1000000, rndseed = rndseed, is.Y.bin = FALSE)$Odata
psi0.Y <- mean(indPop.iid.bA.cY$Y1) - mean(indPop.iid.bA.cY$Y0) # 2.80026
indSample.iid.bA.cY <- get.iid.dat.Abin(ndata = ndata, rndseed = rndseed)$Odata
N <- NROW(indSample.iid.bA.cY)
indSample.iid.bA.cY <- indSample.iid.bA.cY[, c("W1", "W2", "W3", "W4", "A", "Y")]
Qform.corr <- "Y ~ W1 + W2 + W3 + W4 + A" # correct Q
Qform.mis <- "Y ~ W3 + A" # incorrect Q
gform.corr <- "A ~ W1 + W2 + W3 * W4"  # correct g
gform.mis <- "A ~ W1 + W3"  # incorrect g
get.iid.dat.Abin <- function(ndata = 100000, rndseed = NULL, is.Y.bin = TRUE) {
require(simcausal)
D <- DAG.empty()
D <- D +
node("W1", distr = "rbern", prob = 0.5) +
node("W2", distr = "rbern", prob = 0.3) +
node("W3", distr = "rnorm", mean = 0, sd = 0.3) +
node("W4", distr = "runif", min = 0, max = 1) +
node("W3W4", distr = "rconst", const = W3 * W4) +
node("A", distr = "rbern", prob = plogis(0.86 * W1 + W2 + 1.32 * W3 - W4 - 0.45 *W3W4 + 0.1)) +
node("Y", distr = "rnorm", mean = (2.8 * A + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y1", distr = "rnorm", mean = (2.8 * 1 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y0", distr = "rnorm", mean = (2.8 * 0 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1)
D <- set.DAG(D)
Odata <- sim(D, n = ndata, rndseed = rndseed)
psi0.Y <- mean(Odata$Y1) - mean(Odata$Y0)
print("psi0.Y: " %+% psi0.Y)
return(list(psi0.Y = psi0.Y, Odata = Odata))
}
`%+%` <- function(a, b) paste0(a, b)
ndata <- 10000
rndseed <- 12345
indPop.iid.bA.cY <- get.iid.dat.Abin(ndata = 1000000, rndseed = rndseed, is.Y.bin = FALSE)$Odata
psi0.Y <- mean(indPop.iid.bA.cY$Y1) - mean(indPop.iid.bA.cY$Y0) # 2.80026
indSample.iid.bA.cY <- get.iid.dat.Abin(ndata = ndata, rndseed = rndseed)$Odata
N <- NROW(indSample.iid.bA.cY)
indSample.iid.bA.cY <- indSample.iid.bA.cY[, c("W1", "W2", "W3", "W4", "A", "Y")]
Qform.corr <- "Y ~ W1 + W2 + W3 + W4 + A" # correct Q
Qform.mis <- "Y ~ W3 + A" # incorrect Q
gform.corr <- "A ~ W1 + W2 + W3 * W4"  # correct g
gform.mis <- "A ~ W1 + W3"  # incorrect g
require("sl3"); require("SuperLearner")
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = list(glm_fast = sl3::make_learner(sl3::Lrnr_glm_fast)),
sl3_metalearner = sl3::make_learner(sl3::Lrnr_optim, loss_function = sl3::loss_loglik_binomial,
learner_function = sl3::metalearner_logistic_binomial))
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A",
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
remotes::install_github("chizhangucb/tmleCommunity")
get.iid.dat.Abin <- function(ndata = 100000, rndseed = NULL, is.Y.bin = TRUE) {
require(simcausal)
D <- DAG.empty()
D <- D +
node("W1", distr = "rbern", prob = 0.5) +
node("W2", distr = "rbern", prob = 0.3) +
node("W3", distr = "rnorm", mean = 0, sd = 0.3) +
node("W4", distr = "runif", min = 0, max = 1) +
node("W3W4", distr = "rconst", const = W3 * W4) +
node("A", distr = "rbern", prob = plogis(0.86 * W1 + W2 + 1.32 * W3 - W4 - 0.45 *W3W4 + 0.1)) +
node("Y", distr = "rnorm", mean = (2.8 * A + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y1", distr = "rnorm", mean = (2.8 * 1 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y0", distr = "rnorm", mean = (2.8 * 0 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1)
D <- set.DAG(D)
Odata <- sim(D, n = ndata, rndseed = rndseed)
psi0.Y <- mean(Odata$Y1) - mean(Odata$Y0)
print("psi0.Y: " %+% psi0.Y)
return(list(psi0.Y = psi0.Y, Odata = Odata))
}
`%+%` <- function(a, b) paste0(a, b)
ndata <- 10000
rndseed <- 12345
indPop.iid.bA.cY <- get.iid.dat.Abin(ndata = 1000000, rndseed = rndseed, is.Y.bin = FALSE)$Odata
psi0.Y <- mean(indPop.iid.bA.cY$Y1) - mean(indPop.iid.bA.cY$Y0) # 2.80026
indSample.iid.bA.cY <- get.iid.dat.Abin(ndata = ndata, rndseed = rndseed)$Odata
N <- NROW(indSample.iid.bA.cY)
indSample.iid.bA.cY <- indSample.iid.bA.cY[, c("W1", "W2", "W3", "W4", "A", "Y")]
Qform.corr <- "Y ~ W1 + W2 + W3 + W4 + A" # correct Q
Qform.mis <- "Y ~ W3 + A" # incorrect Q
gform.corr <- "A ~ W1 + W2 + W3 * W4"  # correct g
gform.mis <- "A ~ W1 + W3"  # incorrect g
require("sl3"); require("SuperLearner")
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = list(glm_fast = sl3::make_learner(sl3::Lrnr_glm_fast)),
sl3_metalearner = sl3::make_learner(sl3::Lrnr_optim, loss_function = sl3::loss_loglik_binomial,
learner_function = sl3::metalearner_logistic_binomial))
library(tmleCommunity)
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = list(glm_fast = sl3::make_learner(sl3::Lrnr_glm_fast)),
sl3_metalearner = sl3::make_learner(sl3::Lrnr_optim, loss_function = sl3::loss_loglik_binomial,
learner_function = sl3::metalearner_logistic_binomial))
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A",
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
estimates <- tmleCom_res$ATE$estimates  # psi0 = 2.80026
estimates
expect_equal(estimates["tmle", ], 2.799400, tolerance = 1e-6)
expect_equal(estimates["iptw", ], 2.820582, tolerance = 1e-6)
library(testthat)
expect_equal(estimates["tmle", ], 2.799400, tolerance = 1e-6)
expect_equal(estimates["iptw", ], 2.820582, tolerance = 1e-6)
expect_equal(estimates["gcomp", ], 2.779068, tolerance = 1e-6)
require("SuperLearner")
tmleCom_Options(Qestimator = "SuperLearner", gestimator = "SuperLearner", maxNperBin = N,
SL.library = c("SL.glm", "SL.step", "SL.glm.interaction"))
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A",
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0,
Qform = NULL, hform.g0 = NULL, hform.gstar = NULL, rndseed = 12345)
sl3_learners <- list(
#rf = sl3::make_learner(sl3::Lrnr_randomForest),
#xgb = sl3::make_learner(sl3::Lrnr_xgboost),
glmnet = sl3::make_learner(sl3::Lrnr_glmnet),
glm_fast = sl3::make_learner(sl3::Lrnr_glm_fast)
#glm_fast_true_covars = make_learner(Lrnr_glm_fast, covariates = "W1"),
mean = sl3::make_learner(sl3::Lrnr_mean)
)
sl3_learners <- list(
#rf = sl3::make_learner(sl3::Lrnr_randomForest),
#xgb = sl3::make_learner(sl3::Lrnr_xgboost),
glmnet = sl3::make_learner(sl3::Lrnr_glmnet),
glm_fast = sl3::make_learner(sl3::Lrnr_glm_fast),
#glm_fast_true_covars = make_learner(Lrnr_glm_fast, covariates = "W1"),
mean = sl3::make_learner(sl3::Lrnr_mean)
)
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = sl3_learners,
sl3_metalearner = sl3::make_learner(sl3::Lrnr_optim, loss_function = sl3::loss_loglik_binomial,
learner_function = sl3::metalearner_logistic_binomial))
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A",
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
estimates <- tmleCom_res$ATE$estimates  # psi0 = 2.80026
estimates
expect_equal(estimates["tmle", ], 2.799400, tolerance = 1e-6)
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "speedglm__glm")
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "glm__glm")
# 1.2 using SuperLearner
library(SuperLearner)
# library including "SL.glm", "SL.glmnet", "SL.ridge", and "SL.stepAIC"
tmleCom_Options(Qestimator = "SuperLearner", gestimator = "SuperLearner", CVfolds = 5,
SL.library = c("SL.glm", "SL.glmnet", "SL.ridge", "SL.stepAIC"))
# library including "SL.bayesglm", "SL.gam", and "SL.randomForest", and split to 10 CV folds
# require("gam"); require("randomForest")
tmleCom_Options(Qestimator = "SuperLearner", gestimator = "SuperLearner", CVfolds = 10,
SL.library = c("SL.bayesglm", "SL.gam", "SL.randomForest"))
# Create glmnet wrappers with different alphas (the default value of alpha in SL.glmnet is 1)
create.SL.glmnet <- function(alpha = c(0.25, 0.50, 0.75)) {
for(mm in seq(length(alpha))){
eval(parse(text = paste('SL.glmnet.', alpha[mm], '<- function(..., alpha = ',
alpha[mm], ') SL.glmnet(..., alpha = alpha)', sep = '')),
envir = .GlobalEnv)
}
invisible(TRUE)
}
create.SL.glmnet(seq(0, 1, length.out=3))  # 3 glmnet wrappers with alpha = 0, 0.5, 1
# Create custom randomForest learners (set ntree to 100 rather than the default of 500)
create.SL.rf <- create.Learner("SL.randomForest", list(ntree = 100))
# Create a sequence of 3 customized KNN learners
# set the number of nearest neighbors as 8 and 12 rather than the default of 10
create.SL.Knn <- create.Learner("SL.kernelKnn", detailed_names=TRUE, tune=list(k=c(8, 12)))
SL.library <- c(grep("SL.glmnet.", as.vector(lsf.str()), value=TRUE),
create.SL.rf$names, create.SL.Knn$names)
tmleCom_Options(Qestimator = "SuperLearner", gestimator = "SuperLearner",
SL.library = SL.library, CVfolds = 5)
# 1.3 using h2o.ensemble
library("h2o"); library("h2oEnsemble")
# h2olearner including "h2o.glm.wrapper" and "h2o.randomForest.wrapper"
tmleCom_Options(Qestimator = "h2o__ensemble", gestimator = "h2o__ensemble",
CVfolds = 10, h2ometalearner = "h2o.glm.wrapper",
h2olearner = c("h2o.glm.wrapper", "h2o.randomForest.wrapper"))
# Create a sequence of customized h2o glm, randomForest and deeplearning wrappers
h2o.glm.1 <- function(..., alpha = 1, prior = NULL) {
h2o.glm.wrapper(..., alpha = alpha, , prior=prior)
}
h2o.glm.0.5 <- function(..., alpha = 0.5, prior = NULL) {
h2o.glm.wrapper(..., alpha = alpha, , prior=prior)
}
h2o.randomForest.1 <- function(..., ntrees = 200, nbins = 50, seed = 1) {
h2o.randomForest.wrapper(..., ntrees = ntrees, nbins = nbins, seed = seed)
}
h2o.deeplearning.1 <- function(..., hidden = c(500, 500), activation = "Rectifier", seed = 1) {
h2o.deeplearning.wrapper(..., hidden = hidden, activation = activation, seed = seed)
}
h2olearner <- c("h2o.glm.1", "h2o.glm.0.5", "h2o.randomForest.1",
"h2o.deeplearning.1", "h2o.gbm.wrapper")
tmleCom_Options(Qestimator = "h2o__ensemble", gestimator = "h2o__ensemble",
SL.library = c("SL.glm", "SL.glmnet", "SL.ridge", "SL.stepAIC"), CVfolds = 5,
h2ometalearner = "h2o.deeplearning.wrapper", h2olearner = h2olearner)
# using "h2o.deeplearning.wrapper" for h2ometalearner
tmleCom_Options(Qestimator = "h2o__ensemble", gestimator = "h2o__ensemble",
SL.library = c("SL.glm", "SL.glmnet", "SL.ridge", "SL.stepAIC"), CVfolds = 5,
h2ometalearner = "h2o.deeplearning.wrapper", h2olearner = h2olearner)
#***************************************************************************************
# Example 2: Define the values of bin cutoffs for continuous outcome in different ways
# through three arguments - bin.method, nbins, maxNperBin
#***************************************************************************************
# 2.1 using equal-length method
# discretize a continuous outcome variable into 10 bins, no more than 1000 obs in each bin
tmleCom_Options(bin.method = "equal.len", nbins = 10, maxNperBin = 1000)
# 2.2 find a compromise between equal-mass and equal-length method
# discretize into 5 bins (default), and no more than 5000 obs in each bin
tmleCom_Options(bin.method = "dhist", nbins = 10, maxNperBin = 5000)
# 2.3 Default to use equal-mass method with 5 bins, no more than 500 obs in each bin
tmleCom_Options()
# 1.4 using sl3
library(sl3)
Lrnr_pkg_SuperLearner_screener
slscreener <- Lrnr_pkg_SuperLearner_screener$new("screen.glmnet")
glm_learner <- Lrnr_glm$new()
screen_and_glm <- Pipeline$new(slscreener, glm_learner)
sl3_learners <- list(
rf = make_learner(Lrnr_randomForest),
#xgb = make_learner(Lrnr_xgboost),
#glmnet = make_learner(Lrnr_glmnet),
glm_fast = make_learner(Lrnr_glm_fast),
screened_glm = screen_and_glm,
mean = make_learner(Lrnr_mean)
)
logit_metalearner <- make_learner(
Lrnr_optim,
loss_function = loss_loglik_binomial,
learner_function = metalearner_logistic_binomial
)
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = sl3_learners, sl3_metalearner = logit_metalearner)
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A", verbose = TRUE,
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
get.iid.dat.Abin <- function(ndata = 100000, rndseed = NULL, is.Y.bin = TRUE) {
require(simcausal)
D <- DAG.empty()
D <- D +
node("W1", distr = "rbern", prob = 0.5) +
node("W2", distr = "rbern", prob = 0.3) +
node("W3", distr = "rnorm", mean = 0, sd = 0.3) +
node("W4", distr = "runif", min = 0, max = 1) +
node("W3W4", distr = "rconst", const = W3 * W4) +
node("A", distr = "rbern", prob = plogis(0.86 * W1 + W2 + 1.32 * W3 - W4 - 0.45 *W3W4 + 0.1)) +
node("Y", distr = "rnorm", mean = (2.8 * A + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y1", distr = "rnorm", mean = (2.8 * 1 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1) +
node("Y0", distr = "rnorm", mean = (2.8 * 0 + 2 * W1 + 1.5 * W2 + 0.5 * W3 - 3 * W4 - 3.5), sd = 1)
D <- set.DAG(D)
Odata <- sim(D, n = ndata, rndseed = rndseed)
psi0.Y <- mean(Odata$Y1) - mean(Odata$Y0)
print("psi0.Y: " %+% psi0.Y)
return(list(psi0.Y = psi0.Y, Odata = Odata))
}
`%+%` <- function(a, b) paste0(a, b)
ndata <- 10000
rndseed <- 12345
indPop.iid.bA.cY <- get.iid.dat.Abin(ndata = 1000000, rndseed = rndseed, is.Y.bin = FALSE)$Odata
psi0.Y <- mean(indPop.iid.bA.cY$Y1) - mean(indPop.iid.bA.cY$Y0) # 2.80026
indSample.iid.bA.cY <- get.iid.dat.Abin(ndata = ndata, rndseed = rndseed)$Odata
N <- NROW(indSample.iid.bA.cY)
indSample.iid.bA.cY <- indSample.iid.bA.cY[, c("W1", "W2", "W3", "W4", "A", "Y")]
Qform.corr <- "Y ~ W1 + W2 + W3 + W4 + A" # correct Q
Qform.mis <- "Y ~ W3 + A" # incorrect Q
gform.corr <- "A ~ W1 + W2 + W3 * W4"  # correct g
gform.mis <- "A ~ W1 + W3"  # incorrect g
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A", verbose = TRUE,
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
sl3Options("sl3.verbose")
estimates <- tmleCom_res$ATE$estimates  # psi0 = 2.80026
estimates
sl3_learners <- list(
#rf = make_learner(Lrnr_randomForest),
#xgb = make_learner(Lrnr_xgboost),
#glmnet = make_learner(Lrnr_glmnet),
glm_fast = make_learner(Lrnr_glm_fast),
screened_glm = screen_and_glm,
#mean = make_learner(Lrnr_mean)
)
logit_metalearner <- make_learner(
Lrnr_optim,
loss_function = loss_loglik_binomial,
learner_function = metalearner_logistic_binomial
)
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = sl3_learners, sl3_metalearner = logit_metalearner)
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A", verbose = TRUE,
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
sl3Options("sl3.verbose", TRUE)
estimates <- tmleCom_res$ATE$estimates  # psi0 = 2.80026
estimates
sl3_learners <- list(
#rf = make_learner(Lrnr_randomForest),
#xgb = make_learner(Lrnr_xgboost),
#glmnet = make_learner(Lrnr_glmnet),
glm_fast = make_learner(Lrnr_glm_fast)
#screened_glm = screen_and_glm,
#mean = make_learner(Lrnr_mean)
)
logit_metalearner <- make_learner(
Lrnr_optim,
loss_function = loss_loglik_binomial,
learner_function = metalearner_logistic_binomial
)
sl3Options("sl3.verbose", TRUE)
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = sl3_learners, sl3_metalearner = logit_metalearner)
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A", verbose = TRUE,
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
estimates <- tmleCom_res$ATE$estimates  # psi0 = 2.80026
estimates
sl3_learners <- list(
#rf = make_learner(Lrnr_randomForest),
#xgb = make_learner(Lrnr_xgboost),
#glmnet = make_learner(Lrnr_glmnet),
glm_fast = make_learner(Lrnr_glm_fast),
screened_glm = screen_and_glm
#mean = make_learner(Lrnr_mean)
)
logit_metalearner <- make_learner(
Lrnr_optim,
loss_function = loss_loglik_binomial,
learner_function = metalearner_logistic_binomial
)
sl3Options("sl3.verbose", TRUE)
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learners = sl3_learners, sl3_metalearner = logit_metalearner)
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A", verbose = TRUE,
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
estimates <- tmleCom_res$ATE$estimates  # psi0 = 2.80026
estimates
require("sl3"); require("SuperLearner")
tmleCom_Options(Qestimator = "speedglm__glm", gestimator = "sl3_pipelines", maxNperBin = N, nbins = 5,
sl3_learner = list(glm_fast = sl3::make_learner(sl3::Lrnr_glm_fast)),
sl3_metalearner = sl3::make_learner(sl3::Lrnr_optim, loss_function = sl3::loss_loglik_binomial,
learner_function = sl3::metalearner_logistic_binomial))
tmleCom_res <-
tmleCommunity(data = indSample.iid.bA.cY, Ynode = "Y", Anodes = "A",
WEnodes = c("W1", "W2", "W3", "W4"), f_gstar1 = 1, f_gstar2 = 0, rndseed = 12345)
estimates <- tmleCom_res$ATE$estimates  # psi0 = 2.80026
estimates
expect_equal(estimates["tmle", ], 2.799400, tolerance = 1e-6)
expect_equal(estimates["iptw", ], 2.820582, tolerance = 1e-6)
expect_equal(estimates["gcomp", ], 2.779068, tolerance = 1e-6)
library(devtools)
library(usethis)
library(roxygen2)
### Step 4. Document Functions & Generate pdf file from Rd files
# library(R6)
devtools::document()
file.remove(file.path(getwd(),"tmleCommunity.pdf"))
path <- find.package("tmleCommunity")
system(paste(shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)))
make_learner(Lrnr_svm)
install_github("e1071")
install.packages("e1071")
library(e1071)
make_learner(Lrnr_svm)
### Step 4. Document Functions & Generate pdf file from Rd files
# library(R6)
devtools::document()
file.remove(file.path(getwd(),"tmleCommunity.pdf"))
path <- find.package("tmleCommunity")
system(paste(shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)))
file.remove(file.path(getwd(),"tmleCommunity.pdf"))
system(paste(shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)))
system(paste(shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)))
### Step 4. Document Functions & Generate pdf file from Rd files
# library(R6)
devtools::document()
file.remove(file.path(getwd(),"tmleCommunity.pdf"))
path <- find.package("tmleCommunity")
system(paste(shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)))
### Step 4. Document Functions & Generate pdf file from Rd files
# library(R6)
devtools::document()
### Step 4. Document Functions & Generate pdf file from Rd files
# library(R6)
devtools::document()
